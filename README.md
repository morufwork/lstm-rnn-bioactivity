# LSTM-Based Bioactivity Prediction of Chemical Compounds

# Project Overview
This project leverages Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNNs) to predict the bioactivity of chemical compounds targeting acetylcholinesterase (AChE)â€”a key enzyme involved in Alzheimer's disease therapy. Unlike traditional cheminformatics approaches that rely on molecular fingerprint descriptors, our model learns representations directly from SMILES strings, allowing for more flexibility and reduced need for manual feature engineering.

## ğŸ” Key Features

- ğŸ§ª **Dataset of 4,620 compounds** from the [ChEMBL](https://www.ebi.ac.uk/chembl/) database  
- ğŸ”¬ **Evaluated on 1,000 unlabeled compounds** from [ZINC-20](https://zinc.docking.org/)  
- ğŸ§  **Sequence-based learning** via character-level SMILES tokenization  
- ğŸ“ˆ **Model trained** using binary cross-entropy loss and optimized with the Adam algorithm  
- âœ… **Performance**: 83% accuracy, 84% precision, 83% recall, 83% F1 score, and 92% AUC  
- ğŸ§  **SHAP analysis** applied to interpret token-level contributions and model decisions

## ğŸ’¡ Motivation

Cheminformatics often struggles with:

- ğŸ”¬ **Complexity in molecular structures**
- ğŸ“‰ **Limited domain-specific expertise for feature crafting**

This project addresses these challenges using **deep learning** to autonomously learn chemical representations directly from data, minimizing the need for manual feature engineering.

## ğŸ§ª Dataset

- **Training Data**: 4,620 labeled compounds from [ChEMBL](https://www.ebi.ac.uk/chembl/)
- **Test Data**: 1,000 randomly selected compounds from [ZINC-20](https://zinc.docking.org/)

## ğŸ§  Model Architecture

- **Input**: Tokenized SMILES strings
- **Embedding Layer**
- **LSTM Layers**
- **Dense Output Layer** (Sigmoid activation)


### âœ… How it will look on GitHub:

---

## ğŸš€ How to Run

```bash
# Clone the repository
git clone https://github.com/morufwork/lstm-rnn-bioactivity.git
cd lstm-rnn-bioactivity

# Install dependencies
pip install -r requirements.txt

# Train the model
python train.py

# Run predictions
python predict.py --input smiles_input.txt
```

## ğŸ”¬ Model Interpretability

**SHAP (SHapley Additive exPlanations)** was used to interpret model predictions. Key insights include:

- ğŸ§¬ **Aliphatic (`"C"`) and aromatic carbon (`"c"`) atoms** were identified as top positive contributors to predicted bioactivity.
- ğŸ“Š The model's learned patterns align with **established structure-activity relationships** in medicinal chemistry, increasing confidence in prediction reliability.




## ğŸ’¡ Applications

- ğŸ’Š **Drug discovery and virtual screening**
- ğŸ§¬ **Interpretability in cheminformatics**
- ğŸ“š **Educational demos for deep learning in bioinformatics**

## ğŸ“„ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.
